大数据开发工程师（spark scala）
1、基于spark scala等构建数据分析平台，进行设计、开发分布式计算业务；
2、基于Spark技术的海量数据的处理、分析、统计和挖掘；
3、基于Spark框架的数据仓库的设计、开发和维护
3、负责数据处理性能调优，对数据库整体架构提出建议；
4、编写系统的需求分析、设计、开发和部署文档等。

任职要求：
1.本科及以上学历，计算机相关专业；
2.3年及以上大数据开发经验；
3.熟悉HDFS/HBase/Hive/MapReduce/spark，有丰富的分布式编程经验；
4.熟悉Spark Streaming和Spark SQL；
5.熟悉Core Java，熟悉Java IO, NIO, 多线程编程， 熟悉JVM运行机制和内存管理，网络协议；
6.熟练掌握Linux操作系统，熟悉shell等脚本编程；
7.有在Spark相关项目中应用Java或Python语言的经验者优先;
8.有过海量数据系统开发经验者优先；
9.有良好的语言沟通能力，能够协调团队成员及相关部门开展分工及合作。
